import sys
import os
import warnings
import shutil
import findspark
import time
from datetime import datetime
from colorama import Fore, Back, Style, init
from tqdm import tqdm
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import LogisticRegression
from pyspark.sql.types import *
import pyspark.sql.functions as F

# Colorama baÅŸlatma
init()
findspark.init("/opt/spark")

def print_banner():
    """Banner yazdÄ±rma"""
    banner = f"""
{Fore.CYAN}
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘             SENSÃ–R HAREKETÄ° ML MODELÄ°                â•‘
â•‘                   EÄŸitim v1.0                        â•‘
â•‘ --------------------------------------------------- â•‘
â•‘  ğŸ“Š Veri HazÄ±rlama | ğŸ¤– Model EÄŸitimi | ğŸ“ˆ Performans  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{Style.RESET_ALL}"""
    print(banner)

def log_message(message, level="info", indent=0):
    """Renkli log mesajlarÄ±"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    colors = {
        "info": Fore.GREEN,
        "warning": Fore.YELLOW,
        "error": Fore.RED + Back.WHITE,
        "highlight": Fore.BLUE,
        "success": Fore.CYAN
    }
    icons = {
        "info": "â„¹ï¸",
        "warning": "âš ï¸",
        "error": "âŒ",
        "highlight": "ğŸ”",
        "success": "âœ…"
    }
    indent_str = "  " * indent
    print(f"{colors.get(level, Fore.WHITE)}[{timestamp}] {icons.get(level, '')} {indent_str}{message}{Style.RESET_ALL}")

def setup_model_directory(model_path):
    """Model dizini hazÄ±rlama"""
    try:
        if os.path.exists(model_path):
            log_message(f"Eski model dizini bulundu: {model_path}", "warning")
            shutil.rmtree(model_path)
            log_message("Eski model temizlendi", "success", indent=1)
        os.makedirs(model_path, exist_ok=True)
        log_message("Model dizini hazÄ±rlandÄ±", "success")
        return True
    except Exception as e:
        log_message(f"Dizin hazÄ±rlama hatasÄ±: {str(e)}", "error")
        return False

def print_performance_report(total, correct, accuracy):
    """Model performans raporu yazdÄ±rma"""
    report = f"""
{Fore.CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• MODEL PERFORMANS RAPORU â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸ“Š Model DeÄŸerlendirmesi:                                 â•‘
â•‘   â”œâ”€â”€ ğŸ“ Toplam Veri    : {total:<28} â•‘
â•‘   â”œâ”€â”€ âœ… DoÄŸru Tahmin   : {correct:<28} â•‘
â•‘   â””â”€â”€ ğŸ¯ DoÄŸruluk OranÄ± : %{accuracy:.2f}{' ':<26} â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Style.RESET_ALL}
"""
    print(report)

def main():
    # Banner yazdÄ±r
    print_banner()
    log_message("ML model eÄŸitimi baÅŸlatÄ±lÄ±yor...", "highlight")

    # Model dizinini hazÄ±rla
    model_path = "/opt/spark/ml_model"
    if not setup_model_directory(model_path):
        sys.exit(1)

    # Spark Session baÅŸlat
    try:
        spark = SparkSession.builder \
            .appName("ML Model Training") \
            .master("local[2]") \
            .config("spark.driver.memory", "4g") \
            .config("spark.executor.memory", "4g") \
            .getOrCreate()
        log_message("Spark Session baÅŸarÄ±yla oluÅŸturuldu!", "success")
    except Exception as e:
        log_message(f"Spark Session hatasÄ±: {str(e)}", "error")
        sys.exit(1)

    # Veri ÅŸemasÄ±
    schema = StructType([
        StructField("event_ts_min", StringType(), True),
        StructField("ts_min_bignt", IntegerType(), True),
        StructField("room", StringType(), True),
        StructField("co2", FloatType(), True),
        StructField("light", FloatType(), True),
        StructField("temp", FloatType(), True),
        StructField("humidity", FloatType(), True),
        StructField("pir", FloatType(), True)
    ])

    # Veri okuma
    try:
        log_message("EÄŸitim verisi okunuyor...", "info")
        df = spark.read.csv("/opt/data-generator/input/sensors.csv", 
                           schema=schema, header=True)
        total_records = df.count()
        log_message(f"Toplam {total_records:,} kayÄ±t okundu", "success", indent=1)
    except Exception as e:
        log_message(f"Veri okuma hatasÄ±: {str(e)}", "error")
        sys.exit(1)

    # Veri hazÄ±rlama
    log_message("Veri Ã¶n iÅŸleme baÅŸlatÄ±lÄ±yor...", "info")
    with tqdm(total=3, desc=f"{Fore.CYAN}Veri HazÄ±rlama{Style.RESET_ALL}", 
              bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt}") as pbar:
        
        # Label oluÅŸtur
        df = df.withColumn("label", F.when(F.col("pir") > 0, 1.0).otherwise(0.0))
        pbar.update(1)
        
        # Feature'larÄ± birleÅŸtir
        assembler = VectorAssembler(
            inputCols=["co2", "light", "temp", "humidity"],
            outputCol="features"
        )
        pbar.update(1)
        
        # EÄŸitim verisi hazÄ±rla
        training_data = assembler.transform(df)
        pbar.update(1)

    # Model eÄŸitimi
    log_message("Model eÄŸitimi baÅŸlatÄ±lÄ±yor...", "highlight")
    try:
        lr = LogisticRegression(
            featuresCol="features",
            labelCol="label",
            maxIter=10
        )
        
        with tqdm(total=100, desc=f"{Fore.CYAN}Model EÄŸitimi{Style.RESET_ALL}", 
                  bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt}") as pbar:
            model = lr.fit(training_data)
            pbar.update(100)
        
        # Modeli kaydet
        model.write().overwrite().save(model_path)
        log_message("Model baÅŸarÄ±yla kaydedildi!", "success")
    except Exception as e:
        log_message(f"Model eÄŸitim hatasÄ±: {str(e)}", "error")
        sys.exit(1)

    # Model performansÄ±
    log_message("Model performansÄ± deÄŸerlendiriliyor...", "info")
    predictions = model.transform(training_data)
    total = predictions.count()
    correct = predictions.filter(F.col("prediction") == F.col("label")).count()
    accuracy = (correct / total) * 100

    # Performans raporu
    print_performance_report(total, correct, accuracy)

    # BaÅŸarÄ±lÄ± tamamlanma mesajÄ±
    log_message("""
    âœ¨ Model eÄŸitimi baÅŸarÄ±yla tamamlandÄ±!
    â”œâ”€â”€ ğŸ’¾ Model Konumu: /opt/spark/ml_model
    â””â”€â”€ ğŸ“Š DoÄŸruluk OranÄ±: {:.2f}%
    """.format(accuracy), "success")

if __name__ == "__main__":
    main()